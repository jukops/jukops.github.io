---
layout: post
title:  "CNN"
date:   2019-07-09 03:29:00
author: Juhyeok Bae
categories: MachineLearning
---
# CNN 소개
CNN은 인공신경망(Neural Network)중에 하나로써, 합성곱(Convolutional)을 이용해 학습하는 기법이다. 현재는 이미지 분석에 많이 사용 되는 머신러닝 기법이다. 이미지 데이터의 경우 Width * Height * Channel로 보통 3차원 으로 구성된다. 그렇기 때문에 Input 데이터의 양이 큰데, 이런 데이터를 Multi-layer Neural Network를 이용해 분석하게 된다면 parameter의 개수가 많아지며 네트워크 구조도 복잡하게 된다. 이런 구조에서 학습을 진행하니 학습시간도 오래 걸리게 된다. CNN에서는 레이어를 거치며 데이터의 크기와 파라메터 수가 작아진다. 따라서 효율적인 이미지 학습을 가능 하도록 한다.

# CNN 구성 layer
- CNN은 아래와 같은 아키텍쳐를 갖는다.  
  일반 multi-layer NN과 비슷하게 보이지만 fully-connected 전 convolutional-layer와 pooling-layer가 들어가는 차이가 있다. 이 두 layer는 구성하는 아키텍쳐에 따라 줄어 들기도 하고 늘어 나기도 한다.
![CNN Arch](/assets/img/cnn-arch.png){:width="400px" height="100px"}

- Input Layer  
  데이터를 입력에 대한 layer이며, 보통 3차원 이미지 데이터를 입력 한다. 데이터는 Weight * Height * Channel로 구성 된다.

- Convolutional Layer  
  Input layer에서 받은 데이터를 기반으로 1차 연산이 이루어 진다. (weight, height) 데이터에 주변값을 특정 값으로 채워서 늘리는 padding을 한다. 그 후 (m,n) 크기의 filter 를 일정 단위인 stride 만큼 이동하며 합성곱 연산을 한다.  
  그렇게 되면 아래와 같은 크기로 데이터의 변형이 이루어 진다.  
  `Height = ( (height + 2*padding - filter_height) / stride ) + 1`  
  `Weight = ( (weight + 2*padding - filter_weight) / stride ) + 1`  
  해당 layer에서 나온 데이터는 pooling-layer에 연결전 활성화 함수를 거치며 보통 ReLU를 사용한다.

- Pooling Layer  
  앞 layer인 convolutional-layer에서 나온 데이터를 축소 하는 역할을 가지고 있다. window size와 stride 값을 통해서 데이터 크기를 줄이게 된다. 데이터에서 window size 를 대조하여 기준에 따라 큰 값이나 평균 값등을 찾아낸다. 찾고 난 후에는 stride 값만큼 이동하여 계속해 연산을 진행한다. 값을 찾는 기준은 크게 2가지가 있는데, max-pooling의 경우 window 중 제일 큰값, average-pooling의 경우는 평균 값을 반환한다.
  만약 왼쪽의 데이터가 (2,2) window를 가지며, stride size가 2라면 오른쪽과 같은 결과를 갖는다.
  ```
  2301        45
  4253   ->  34
  1342
  0011
  ```

# 예제
Kaggle에 있는 Chest X-Ray Images (Pneumonia) 를 이용 하였으며, Keras를 활용해 구현 하도록 한다.

- import library
  ```
  import numpy as np
  import matplotlib.pyplot as plt
  import os
  from PIL import Image
  import glob

  # Keras Libraries
  import keras
  from keras.models import Sequential
  from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout
  from keras.preprocessing.image import ImageDataGenerator, load_img
  from keras.callbacks import ModelCheckpoint, EarlyStopping
  ```
- path 변수 셋팅
  ```
  train_dir= './dataset/chest_xray/train/'
  val_dir = './dataset/chest_xray/val/'
  test_dir = './dataset/chest_xray/test/'

  train_nor = train_dir + 'NORMAL/'
  train_pne = train_dir + 'PNEUMONIA/'
  train_nor_size = len(glob.glob(train_nor + '*.jpeg'))
  train_pne_size = len(glob.glob(train_pne + '*.jpeg'))
  ```
- 샘플 이미지 확인
  ```
  # show normal image
  nor_img = Image.open(train_nor + os.listdir(train_nor)[0])
  plt.imshow(nor_img)
  plt.title('Normal')
  plt.show()
  ```
  ```
  # show pneumonia image
  pne_img = Image.open(train_pne + os.listdir(train_pne)[0])
  plt.imshow(pne_img)
  plt.title('Pneumonia')
  plt.show()
  ```
- Parameter 셋업
  ```
  my_batch_size = 32
  my_train_data_size = train_nor_size + train_pne_size
  my_test_data_size = 624
  my_validation_data_size = 16
  fc_layer_activation = 'sigmoid'
  ```
- CNN model 생성
  ```
  # Load model
  cnn_model = Sequential()

  # 1st Conv layer
  cnn_model.add(Conv2D(32,kernel_size=(3, 3), activation="relu", input_shape=(64, 64, 3))

  # 1st Pooling layer
  cnn_model.add(MaxPooling2D(pool_size = (2, 2)))

  # 2nd Conv layer
  cnn_model.add(MaxPooling2D(pool_size = (2, 2)))

  # 2nd Pooling layer
  cnn_model.add(MaxPooling2D(pool_size = (2, 2)))

  # Flatten
  cnn_model.add(Flatten())

  # Fully connected layer
  cnn_model.add(Dense(activation = 'relu', units = 128))

  # Dropout layer
  cnn_model.add(Dropout(0.25))

  cnn_model.add(Dense(activation = fc_layer_activation, units = 1))

  # compile Neural network
  cnn_model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])
  ```
- Fit 이미지
  ```
  # Training image 전처리
  train_datagen = ImageDataGenerator(rescale = 1./255,shear_range = 0.2,zoom_range = 0.2,horizontal_flip = True)

  # Training image 로딩
  training_dataset = train_datagen.flow_from_directory('./dataset/chest_xray/train', target_size = (64, 64), batch_size = my_batch_size, class_mode = 'binary')

  # test image 전처리
  test_datagen = ImageDataGenerator(rescale = 1./255)

  # test image 로딩
  test_dataset = test_datagen.flow_from_directory('./dataset/chest_xray/test', target_size = (64, 64), batch_size = my_batch_size, class_mode = 'binary')

  # validation image 전처리
  validation_datagen = ImageDataGenerator(rescale = 1./255)

  # validation image 로딩
  validation_dataset = validation_datagen.flow_from_directory('./dataset/chest_xray/val/', target_size=(64, 64), batch_size=my_batch_size, class_mode='binary')
  ```
- model shape 체크
  ```
  cnn_model.summary()
  ```
  ![CNN shape](/assets/img/cnn-shape.png)

- model 학습
  ```
  my_cnn_model = cnn_model.fit_generator(training_dataset,
                         steps_per_epoch = my_train_data_size / my_batch_size,
                         epochs = 10,
                         validation_data = validation_dataset,
                         validation_steps = 16)
  ```
- 학습된 모델 테스트 데이터 적용
  ```
  test_step = int(my_test_data_size / my_batch_size)
  test_score = cnn_model.evaluate_generator(test_dataset, steps=my_test_data_size / my_batch_size)
  ```
- 테스트 데이터 정확도 확인
  ```
  print("%s: %.2f%%" %(cnn_model.metrics_names[1], test_score[1]*100))
  print("batch size: ", my_batch_size)
  ```
  ![CNN shape](/assets/img/cnn-accuracy.png)
